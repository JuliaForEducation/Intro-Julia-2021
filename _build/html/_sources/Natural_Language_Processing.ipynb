{
    "cells": [
    {
 	    "cell_type": "markdown", 
 	    "source": [ 
 		"# Natural Language Processing" 
 	    ], 
 	    "metadata": {} 
	},
        {
            "cell_type": "markdown",
            "source": [
                "## Marco teórico\n",
                "El procesamiento de lenguaje natural, mencionado como NLP a partir de ahora por sus siglas en inglés (Natural Language Processing), Es una rama de la inteligencia artficial que busca realizar análisis y transformaciones a cuerpos de texto para encontrar patrones, inferir significados y relaciones entre elementos (palabras, párrafos, oraciones, etc.) o, en general, servir en un modelo con algún propósito de toma de decisiones, inferencia o predicción.\n",
                "\n",
                "Aquí veremos los básicos de esta área utilizando el paquete `TextAnalysis` en Julia.\n",
                "\n",
                "### Documentos\n",
                "Los documentos se definen como cualquier cuerpo de texto que puede ser representado de alguna manera específica en el disco de la computadora. Existen los siguientes tipos:\n",
                "- Tipo archivo (FileDocument): Un documento representado como texto plano en el disco.\n",
                "- Tipo string (StringDocument): Un documento representado como un string codificado en UTF8 en memoria RAM\n",
                "- Tipo Token: (TokenDocument): Un documento representado como una sucesión de tokens UTF8, es decir, palabras o símbolos individuales (strings tras ser 'tokenizados').\n",
                "- Tipo N-grama: (NGramDocument): Un documento representado como una colección de pares donde un elemento es un token y el otro es un entero que representa el una frecuencia de ocurrencia de dicho string.\n",
                "\n",
                "Observemos los tipos continuación:\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "using TextAnalysis\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 410
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Documentos de tipo string/cadena\n",
                "Los documentos de tipo cadena suelen ser oraciones individuales, párrafos o textos más completos. No obstante, parte de tener una conjunto de datos limpio yace en organizar los textos en archivo o más pequeño posible.\n",
                "\n",
                "Además, éstos se guardan en memoria ram, representados como una cadena de bits en codificación UTF-8. Por ello, tener textos muy grandes localizados en una sola variable identificadora puede dificultar su manipulación.\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "str = \"Este es un texto de prueba. Este es la segunda oración\"\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 411
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "sd = StringDocument(str)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 412
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Documentos de tipo archivo\n",
                "\n",
                "Los documentos de tipo archivo se utilizan cuando tenemos un archivo contenedor del texto que queremos analizar. Para generarlo en julia basta con poner la ruta hacia el archivo:\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "pathname = \"./nlp/archivo.txt\"\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 413
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "fd = FileDocument(pathname)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 414
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Documentos de tipo token\n",
                "Los token en el contexto de procesamiento de lenguaje natural son elementos individuales y uniformes que yacen en una colección. Se habla de token usualmente para referirse a palabras individuales cuando tenemos un alfabtero latino, no obstante, para otros alfabetos puede que el concepto cambie ligeramente.\n",
                "\n",
                "Además, los tokens podrían referirse a letras individuales, oraciones o cualquier forma de agrupar el texto que posea información estructural. No obstante, esas dos agrupaciones mencionadas no suelen poseer información útil al ser respectivamente muy pequeñas y muy grandes.\n",
                "\n",
                "Para crearlas en Julia podemos crear un arreglo de ellas:\n",
                "\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "mis_tokens = String[\"Esta\", \"es\", \"una\", \"oración\", \"de\", \"prueba\"]\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 415
        },
        {
            "cell_type": "markdown",
            "source": [
                "Aquí aprovechamos a mostrar además que para crear arreglos de un tipo uniforme en Julia, podemos anteponer el nombre del tipo y el compilador sabrá que debe esperar y forzar dicho tipo (ejemplo, `Int32` en un arreglo forzaría a todos los `Integer` dentro a que sean representado por 32 bits)\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "typeof(mis_tokens)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 416
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "td = TokenDocument(mis_tokens)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 417
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Documento de tipo N-grama\n",
                "Podemos pensar en que el documento de tipo token puede ser generado a partir de un documento de tipo string, y así también el de tipo string ser generado a partir de uno de tipo archivo. Esto es correcto y existen métodos específicos para ello.\n",
                "\n",
                "Por una parte, para pasar de un string a una lista de tokens podemos utilizar el paquete `WordTokenizer`, el cual tiene múltiples métodos de tokenización de alto rendimiento para procesar grandes cuerpos de texto y reducirlos a tokens listos para el análisis.\n",
                "\n",
                "Ahora, el documento de tipo N-grama tiene más sentido pensarlo viniendo de uno de tipo token, pues al tokenizar un texto grande, es muy probable que tengamos palabras repetidas y obtener la frecuencia en la que éstas palabras ocurren a lo largo de dicho texto juega un rol en el análisis exploratorio inicial.\n",
                "\n",
                "Los documento de tipo N-grama son precisamente pares de tokens con un número entero que cuenta las ocurrencias de dicho token en algún texto. Aquí podemos generarlo de las siguientes maneras:\n",
                "\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "dict_ocurrencias = Dict(\"hola\" => 1, \"mundo\" => 1)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 418
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "ngd = NGramDocument(dict_ocurrencias)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 419
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Procesamiento \n",
                "### Funciones\n",
                "La siguiente es una exploración a algunas funciones ya definidas (para todos los tipos anteriores mediante multiple dispatch) en el paquete.\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Texto\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "text(sd), text(fd), text(td)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 420
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Tokens\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "tokens(sd)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 421
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                " tokens(fd)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 422
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### N-gramas\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "ngrams(sd)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 423
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "ngrams(fd)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 424
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "ngrams(sd, 2)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 425
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "ngrams(sd, 2, 3)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 426
        },
        {
            "cell_type": "markdown",
            "source": [
                "Podemos también extraer la estructura de un documento de N-gramas para entender si tiene bigramas o trigramas, etc.\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "ngram_complexity(NGramDocument(ngrams(sd), 2))\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 427
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Metadata\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "language(sd) ## El lenguaje por defecto es inglés...\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 428
        },
        {
            "cell_type": "markdown",
            "source": [
                "Podemos cambiarlo utilizando la versión 'mutadora' de la función `language`:\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "language!(sd, TextAnalysis.Languages.Spanish())\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 429
        },
        {
            "cell_type": "markdown",
            "source": [
                "Así igual los demás elementos de la metadata...\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "title(sd), author(sd), timestamp(sd)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 430
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "title!(sd, \"Mi título\"), author!(sd, \"Yo\"), timestamp!(sd, \"Desconocido\")\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 431
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "sd\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 432
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Procesamiento de documentos\n",
                "Antes de comenzar a hacer transformaciones y análisis a los documentos, nos puede interesar hacer una limpieza en caso de tener caracteres corruptos o pequeñas molestias de formato que nos haría más limpio nuestro trabajo si no estuvieran\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "remove_corrupt_utf8!(sd) ## <- ejemplo de ello\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 433
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "str_2 = StringDocument(\"HolA!!!,. Soy un teXto, que No está mUy Bien escrito..\")\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 434
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "prepare!(str_2, strip_punctuation)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 435
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "text(str_2)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 436
        },
        {
            "cell_type": "markdown",
            "source": [
                "Removiendo las mayúsculas...\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "remove_case!(str_2)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 437
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "text(str_2)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 438
        },
        {
            "cell_type": "markdown",
            "source": [
                "Podemos además remover ciertas palabras..\n"
            ],
            "metadata": {}
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "remove_words!(str_2, [\" no\"])\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 439
        },
        {
            "outputs": [],
            "cell_type": "code",
            "source": [
                "text(str_2)\n",
                "",
                ""
            ],
            "metadata": {},
            "execution_count": 440
        },
        {
            "cell_type": "markdown",
            "source": [
                "Otras posibilidades son:\n",
                "\n",
                "```\n",
                "- prepare!(sd, strip_articles)\n",
                "- prepare!(sd, strip_indefinite_articles)\n",
                "- prepare!(sd, strip_definite_articles)\n",
                "- prepare!(sd, strip_preposition)\n",
                "- prepare!(sd, strip_pronouns)\n",
                "- prepare!(sd, strip_stopwords)\n",
                "- prepare!(sd, strip_numbers)\n",
                "- prepare!(sd, strip_non_letters)\n",
                "- prepare!(sd, strip_spares_terms)\n",
                "- prepare!(sd, strip_frequent_terms)\n",
                "- prepare!(sd, strip_html_tags)\n",
                "```\n",
                "\n",
                "Además de poder ser utilizadas juntas:\n",
                "\n",
                "`prepare!(sd, strip_articles| strip_numbers| strip_html_tags)`\n",
                "\n"
            ],
            "metadata": {}
        }
    ],
    "nbformat_minor": 2,
    "metadata": {
        "language_info": {
            "file_extension": ".jl",
            "mimetype": "application/julia",
            "name": "julia",
            "version": "1.5.1"
        },
        "kernelspec": {
            "name": "julia-1.5",
            "display_name": "Julia 1.5.1",
            "language": "julia"
        }
    },
    "nbformat": 4
}
